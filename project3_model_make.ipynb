{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PH  Temprature  Taste  Odor  Fat  Turbidity  Colour  Grade\n",
      "0     6.6          35      1     0    1          0     254      2\n",
      "1     6.6          36      0     1    0          1     253      2\n",
      "2     8.5          70      1     1    1          1     246      0\n",
      "3     9.5          34      1     1    0          1     255      0\n",
      "4     6.6          37      0     0    0          0     255      1\n",
      "...   ...         ...    ...   ...  ...        ...     ...    ...\n",
      "1054  6.7          45      1     1    0          0     247      1\n",
      "1055  6.7          38      1     0    1          0     255      2\n",
      "1056  3.0          40      1     1    1          1     255      0\n",
      "1057  6.8          43      1     0    1          0     250      2\n",
      "1058  8.6          55      0     1    1          1     255      0\n",
      "\n",
      "[1059 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# data load\n",
    "import pandas as pd\n",
    "\n",
    "data_raw = pd.read_csv(\"data/modified_data.csv\", encoding=\"utf-8\")\n",
    "\n",
    "print(data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PH  Temprature  Colour  Grade  Taste_0  Taste_1  Odor_0  Odor_1  Fat_0   \n",
      "0     6.6          35     254      2        0        1       1       0      0  \\\n",
      "1     6.6          36     253      2        1        0       0       1      1   \n",
      "2     8.5          70     246      0        0        1       0       1      0   \n",
      "3     9.5          34     255      0        0        1       0       1      1   \n",
      "4     6.6          37     255      1        1        0       1       0      1   \n",
      "...   ...         ...     ...    ...      ...      ...     ...     ...    ...   \n",
      "1054  6.7          45     247      1        0        1       0       1      1   \n",
      "1055  6.7          38     255      2        0        1       1       0      0   \n",
      "1056  3.0          40     255      0        0        1       0       1      0   \n",
      "1057  6.8          43     250      2        0        1       1       0      0   \n",
      "1058  8.6          55     255      0        1        0       0       1      0   \n",
      "\n",
      "      Fat_1  Turbidity_0  Turbidity_1  \n",
      "0         1            1            0  \n",
      "1         0            0            1  \n",
      "2         1            0            1  \n",
      "3         0            0            1  \n",
      "4         0            1            0  \n",
      "...     ...          ...          ...  \n",
      "1054      0            1            0  \n",
      "1055      1            1            0  \n",
      "1056      1            0            1  \n",
      "1057      1            1            0  \n",
      "1058      1            0            1  \n",
      "\n",
      "[1059 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# data one-hot encoding\n",
    "data = pd.get_dummies(data_raw, columns=data_raw.columns[2:6], dtype=\"int64\")\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PH  Temprature  Taste  Odor  Fat  Turbidity  Colour  Grade\n",
      "0     6.6          35      1     0    1          0     254      2\n",
      "1     6.6          36      0     1    0          1     253      2\n",
      "2     8.5          70      1     1    1          1     246      0\n",
      "3     9.5          34      1     1    0          1     255      0\n",
      "4     6.6          37      0     0    0          0     255      1\n",
      "...   ...         ...    ...   ...  ...        ...     ...    ...\n",
      "1054  6.7          45      1     1    0          0     247      1\n",
      "1055  6.7          38      1     0    1          0     255      2\n",
      "1056  3.0          40      1     1    1          1     255      0\n",
      "1057  6.8          43      1     0    1          0     250      2\n",
      "1058  8.6          55      0     1    1          1     255      0\n",
      "\n",
      "[1059 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# 일반 data loading\n",
    "import pandas as pd\n",
    "\n",
    "g_data_raw = pd.read_csv(\"data/original_data.csv\", encoding=\"utf-8\")\n",
    "\n",
    "print(g_data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PH  Temprature  Colour  Grade  Taste_0  Taste_1  Odor_0  Odor_1  Fat_0   \n",
      "0     6.6          35     254      2        0        1       1       0      0  \\\n",
      "1     6.6          36     253      2        1        0       0       1      1   \n",
      "2     8.5          70     246      0        0        1       0       1      0   \n",
      "3     9.5          34     255      0        0        1       0       1      1   \n",
      "4     6.6          37     255      1        1        0       1       0      1   \n",
      "...   ...         ...     ...    ...      ...      ...     ...     ...    ...   \n",
      "1054  6.7          45     247      1        0        1       0       1      1   \n",
      "1055  6.7          38     255      2        0        1       1       0      0   \n",
      "1056  3.0          40     255      0        0        1       0       1      0   \n",
      "1057  6.8          43     250      2        0        1       1       0      0   \n",
      "1058  8.6          55     255      0        1        0       0       1      0   \n",
      "\n",
      "      Fat_1  Turbidity_0  Turbidity_1  \n",
      "0         1            1            0  \n",
      "1         0            0            1  \n",
      "2         1            0            1  \n",
      "3         0            0            1  \n",
      "4         0            1            0  \n",
      "...     ...          ...          ...  \n",
      "1054      0            1            0  \n",
      "1055      1            1            0  \n",
      "1056      1            0            1  \n",
      "1057      1            1            0  \n",
      "1058      1            0            1  \n",
      "\n",
      "[1059 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# 일반 data one-hot encoding\n",
    "g_data = pd.get_dummies(g_data_raw, columns=g_data_raw.columns[2:6], dtype=\"int64\")\n",
    "\n",
    "print(g_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 data와 test data 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.drop(\"Grade\", axis=1), data[\"Grade\"], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      PH  Temprature  Colour  Taste_0  Taste_1  Odor_0  Odor_1  Fat_0  Fat_1   \n",
      "666  6.5          37     255        1        0       1       0      1      0  \\\n",
      "562  6.5          36     255        1        0       1       0      0      1   \n",
      "50   6.6          37     255        0        1       0       1      0      1   \n",
      "506  3.0          40     255        0        1       1       0      1      0   \n",
      "338  6.7          45     245        0        1       0       1      0      1   \n",
      "\n",
      "     Turbidity_0  Turbidity_1  \n",
      "666            1            0  \n",
      "562            1            0  \n",
      "50             0            1  \n",
      "506            1            0  \n",
      "338            1            0  \n",
      "\n",
      "(741, 11)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.head())\n",
    "\n",
    "print()\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-점수 표준화\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_train = pd.DataFrame(ss.fit_transform(x_train), columns=x_train.columns, index=x_train.index)\n",
    "\n",
    "x_test = pd.DataFrame(ss.transform(x_test), columns=x_test.columns, index=x_test.index)\n",
    "\n",
    "g_data_d = pd.DataFrame(ss.fit_transform(g_data.drop(\"Grade\", axis=1)), columns=g_data.columns.drop(\"Grade\"), index=g_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           PH  Temprature    Colour   Taste_0   Taste_1    Odor_0    Odor_1   \n",
      "666 -0.078846   -0.787890  0.726929  1.125191 -1.125191  0.864663 -0.864663  \\\n",
      "562 -0.078846   -0.901386  0.726929  1.125191 -1.125191  0.864663 -0.864663   \n",
      "50  -0.009127   -0.787890  0.726929 -0.888738  0.888738 -1.156520  1.156520   \n",
      "506 -2.519041   -0.447400  0.726929 -0.888738  0.888738  0.864663 -0.864663   \n",
      "338  0.060593    0.120083 -1.616065 -0.888738  0.888738 -1.156520  1.156520   \n",
      "\n",
      "        Fat_0     Fat_1  Turbidity_0  Turbidity_1  \n",
      "666  1.453769 -1.453769     1.001350    -1.001350  \n",
      "562 -0.687867  0.687867     1.001350    -1.001350  \n",
      "50  -0.687867  0.687867    -0.998651     0.998651  \n",
      "506  1.453769 -1.453769     1.001350    -1.001350  \n",
      "338 -0.687867  0.687867     1.001350    -1.001350  \n",
      "\n",
      "(741, 11)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.head())\n",
    "\n",
    "print()\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666    1\n",
      "562    1\n",
      "50     2\n",
      "506    0\n",
      "338    1\n",
      "Name: Grade, dtype: int64\n",
      "\n",
      "(741,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.head())\n",
    "\n",
    "print()\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian naive bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "train_hat = model.fit(x_train, y_train).predict(x_train)\n",
    "\n",
    "test_hat = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<train data>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       311\n",
      "           1       0.91      0.91      0.91       253\n",
      "           2       0.88      0.92      0.90       177\n",
      "\n",
      "    accuracy                           0.92       741\n",
      "   macro avg       0.92      0.92      0.92       741\n",
      "weighted avg       0.92      0.92      0.92       741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train에 대한 정확도, 재현율, f1-score 확인\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"<train data>\")\n",
    "print(classification_report(y_train, train_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<test data>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       118\n",
      "           1       0.89      0.88      0.88       121\n",
      "           2       0.83      0.87      0.85        79\n",
      "\n",
      "    accuracy                           0.89       318\n",
      "   macro avg       0.89      0.89      0.89       318\n",
      "weighted avg       0.89      0.89      0.89       318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test에 대한 정확도, 재현율, f1-score 확인\n",
    "print(\"<test data>\")\n",
    "print(classification_report(y_test, test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean accuracy: 0.91\n",
      "test mean accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "# 교차 검증\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(f\"train mean accuracy: {round(cross_val_score(model, x_train, y_train, cv=39).mean(), 2)}\")\n",
    "print(f\"test mean accuracy: {round(cross_val_score(model, x_test, y_test, cv=39).mean(), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_data accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "# 일반 data로 검증\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "g_hat = model.predict(g_data_d)\n",
    "\n",
    "print(\"g_data accuracy:\", round(accuracy_score(g_data[\"Grade\"], g_hat), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-nearest neighbors model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "train_hat = model.fit(x_train, y_train).predict(x_train)\n",
    "\n",
    "test_hat = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<train data>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       311\n",
      "           1       0.98      1.00      0.99       253\n",
      "           2       0.99      0.99      0.99       177\n",
      "\n",
      "    accuracy                           0.99       741\n",
      "   macro avg       0.99      0.99      0.99       741\n",
      "weighted avg       0.99      0.99      0.99       741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train에 대한 정확도, 재현율, f1-score 확인\n",
    "print(\"<train data>\")\n",
    "print(classification_report(y_train, train_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<test data>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       118\n",
      "           1       0.94      0.99      0.96       121\n",
      "           2       0.97      0.94      0.95        79\n",
      "\n",
      "    accuracy                           0.97       318\n",
      "   macro avg       0.97      0.96      0.96       318\n",
      "weighted avg       0.97      0.97      0.97       318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test에 대한 정확도, 재현율, f1-score 확인\n",
    "print(\"<test data>\")\n",
    "print(classification_report(y_test, test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean accuracy: 0.99\n",
      "test mean accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "# 교차 검증\n",
    "print(f\"train mean accuracy: {round(cross_val_score(model, x_train, y_train, cv=39).mean(), 2)}\")\n",
    "print(f\"test mean accuracy: {round(cross_val_score(model, x_test, y_test, cv=39).mean(), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_data accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "# 일반 data로 검증\n",
    "g_hat = model.predict(g_data_d)\n",
    "\n",
    "print(\"g_data accuracy:\", round(accuracy_score(g_data[\"Grade\"], g_hat), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다항 logistic 회귀 model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\")\n",
    "\n",
    "train_hat = model.fit(x_train, y_train).predict(x_train)\n",
    "\n",
    "test_hat = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<train data>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89       311\n",
      "           1       0.94      0.85      0.89       253\n",
      "           2       0.73      0.84      0.78       177\n",
      "\n",
      "    accuracy                           0.86       741\n",
      "   macro avg       0.85      0.86      0.85       741\n",
      "weighted avg       0.87      0.86      0.86       741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train에 대한 정확도, 재현율, f1-score 확인\n",
    "print(\"<train data>\")\n",
    "print(classification_report(y_train, train_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<test data>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85       118\n",
      "           1       0.95      0.83      0.88       121\n",
      "           2       0.71      0.85      0.77        79\n",
      "\n",
      "    accuracy                           0.84       318\n",
      "   macro avg       0.84      0.84      0.84       318\n",
      "weighted avg       0.85      0.84      0.85       318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test에 대한 정확도, 재현율, f1-score 확인\n",
    "print(\"<test data>\")\n",
    "print(classification_report(y_test, test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean accuracy: 0.86\n",
      "test mean accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "# 교차 검증\n",
    "print(f\"train mean accuracy: {round(cross_val_score(model, x_train, y_train, cv=39).mean(), 2)}\")\n",
    "print(f\"test mean accuracy: {round(cross_val_score(model, x_test, y_test, cv=39).mean(), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_data accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "# 일반 data로 검증\n",
    "g_hat = model.predict(g_data_d)\n",
    "\n",
    "print(\"g_data accuracy:\", round(accuracy_score(g_data[\"Grade\"], g_hat), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM(Support Vector Machine)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(kernel=\"poly\")\n",
    "\n",
    "train_hat = model.fit(x_train, y_train).predict(x_train)\n",
    "\n",
    "test_hat = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<train data>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       311\n",
      "           1       0.98      0.89      0.94       253\n",
      "           2       0.83      0.96      0.89       177\n",
      "\n",
      "    accuracy                           0.94       741\n",
      "   macro avg       0.93      0.94      0.93       741\n",
      "weighted avg       0.94      0.94      0.94       741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train에 대한 정확도, 재현율, f1-score 확인\n",
    "print(\"<train data>\")\n",
    "print(classification_report(y_train, train_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<test data>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       118\n",
      "           1       0.96      0.88      0.92       121\n",
      "           2       0.83      0.96      0.89        79\n",
      "\n",
      "    accuracy                           0.93       318\n",
      "   macro avg       0.92      0.93      0.92       318\n",
      "weighted avg       0.93      0.93      0.93       318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test에 대한 정확도, 재현율, f1-score 확인\n",
    "print(\"<test data>\")\n",
    "print(classification_report(y_test, test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean accuracy: 0.93\n",
      "test mean accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "# 교차 검증\n",
    "print(f\"train mean accuracy: {round(cross_val_score(model, x_train, y_train, cv=39).mean(), 2)}\")\n",
    "print(f\"test mean accuracy: {round(cross_val_score(model, x_test, y_test, cv=39).mean(), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_data accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "# 일반 data로 검증\n",
    "g_hat = model.predict(g_data_d)\n",
    "\n",
    "print(\"g_data accuracy:\", round(accuracy_score(g_data[\"Grade\"], g_hat), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM(Support Vector Machine)\n",
    "model = SVC(kernel=\"rbf\")\n",
    "\n",
    "train_hat = model.fit(x_train, y_train).predict(x_train)\n",
    "\n",
    "test_hat = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<train data>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96       311\n",
      "           1       0.95      0.89      0.92       253\n",
      "           2       0.83      0.95      0.89       177\n",
      "\n",
      "    accuracy                           0.93       741\n",
      "   macro avg       0.92      0.93      0.92       741\n",
      "weighted avg       0.93      0.93      0.93       741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train에 대한 정확도, 재현율, f1-score 확인\n",
    "print(\"<train data>\")\n",
    "print(classification_report(y_train, train_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<test data>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94       118\n",
      "           1       0.93      0.88      0.91       121\n",
      "           2       0.83      0.96      0.89        79\n",
      "\n",
      "    accuracy                           0.92       318\n",
      "   macro avg       0.91      0.92      0.91       318\n",
      "weighted avg       0.92      0.92      0.92       318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test에 대한 정확도, 재현율, f1-score 확인\n",
    "print(\"<test data>\")\n",
    "print(classification_report(y_test, test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean accuracy: 0.92\n",
      "test mean accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "# 교차 검증\n",
    "print(f\"train mean accuracy: {round(cross_val_score(model, x_train, y_train, cv=39).mean(), 2)}\")\n",
    "print(f\"test mean accuracy: {round(cross_val_score(model, x_test, y_test, cv=39).mean(), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_data accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "# 일반 data로 검증\n",
    "g_hat = model.predict(g_data_d)\n",
    "\n",
    "print(\"g_data accuracy:\", round(accuracy_score(g_data[\"Grade\"], g_hat), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost model\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "\n",
    "train_hat = model.fit(x_train, y_train).predict(x_train)\n",
    "\n",
    "test_hat = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<train data>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       311\n",
      "           1       1.00      1.00      1.00       253\n",
      "           2       1.00      1.00      1.00       177\n",
      "\n",
      "    accuracy                           1.00       741\n",
      "   macro avg       1.00      1.00      1.00       741\n",
      "weighted avg       1.00      1.00      1.00       741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train에 대한 정확도, 재현율, f1-score 확인\n",
    "print(\"<train data>\")\n",
    "print(classification_report(y_train, train_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<test data>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       118\n",
      "           1       1.00      1.00      1.00       121\n",
      "           2       1.00      1.00      1.00        79\n",
      "\n",
      "    accuracy                           1.00       318\n",
      "   macro avg       1.00      1.00      1.00       318\n",
      "weighted avg       1.00      1.00      1.00       318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test에 대한 정확도, 재현율, f1-score 확인\n",
    "print(\"<test data>\")\n",
    "print(classification_report(y_test, test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean accuracy: 1.0\n",
      "test mean accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 교차 검증\n",
    "print(f\"train mean accuracy: {round(cross_val_score(model, x_train, y_train, cv=39).mean(), 2)}\")\n",
    "print(f\"test mean accuracy: {round(cross_val_score(model, x_test, y_test, cv=39).mean(), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_data accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 일반 data로 검증\n",
    "g_hat = model.predict(g_data_d)\n",
    "\n",
    "print(\"g_data accuracy:\", round(accuracy_score(g_data[\"Grade\"], g_hat), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(max_iter=5000)\n",
    "\n",
    "train_hat = model.fit(x_train, y_train).predict(x_train)\n",
    "\n",
    "test_hat = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<train data>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       311\n",
      "           1       1.00      1.00      1.00       253\n",
      "           2       1.00      1.00      1.00       177\n",
      "\n",
      "    accuracy                           1.00       741\n",
      "   macro avg       1.00      1.00      1.00       741\n",
      "weighted avg       1.00      1.00      1.00       741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train에 대한 정확도, 재현율, f1-score 확인\n",
    "print(\"<train data>\")\n",
    "print(classification_report(y_train, train_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<test data>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       118\n",
      "           1       1.00      1.00      1.00       121\n",
      "           2       1.00      1.00      1.00        79\n",
      "\n",
      "    accuracy                           1.00       318\n",
      "   macro avg       1.00      1.00      1.00       318\n",
      "weighted avg       1.00      1.00      1.00       318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test에 대한 정확도, 재현율, f1-score 확인\n",
    "print(\"<test data>\")\n",
    "print(classification_report(y_test, test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean accuracy: 0.99\n",
      "test mean accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# 교차 검증\n",
    "print(f\"train mean accuracy: {round(cross_val_score(model, x_train, y_train, cv=39).mean(), 2)}\")\n",
    "print(f\"test mean accuracy: {round(cross_val_score(model, x_test, y_test, cv=39).mean(), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_data accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 일반 data로 검증\n",
    "g_hat = model.predict(g_data_d)\n",
    "\n",
    "print(\"g_data accuracy:\", round(accuracy_score(g_data[\"Grade\"], g_hat), 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
